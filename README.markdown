# Cybersecurity Data Science PBL Project - Part 1: Pre-trained Model Validation

## Overview
This part of the PBL project focuses on validating a pre-trained neural network model (`VulnPredictModel`) for vulnerability prediction using a provided dataset (`student_dataset.hdf5`). The dataset contains code samples represented as 768-dimensional vectors labeled as `True` (vulnerable) or `False` (non-vulnerable). The tasks include loading the dataset, inspecting its properties, making predictions, and evaluating performance metrics.

## Repository Structure
- `data_students/student_dataset.hdf5`: Validation dataset containing code vectors and labels.
- `model_2023-03-28_20-03.pth`: Pre-trained model weights for `VulnPredictModel`.
- `part1_validation.py`: Script for loading the dataset, inspecting it, and evaluating the model.
- `README_Part1.md`: This file.

## Requirements
Install the required Python packages:
```bash
pip install torch h5py numpy
```

## Usage
1. Ensure `student_dataset.hdf5` and `model_2023-03-28_20-03.pth` are in the working directory.
2. Run the validation script:
   ```bash
   python part1_validation.py
   ```
3. The script performs the following:
   - Loads the HDF5 dataset using a custom `ValidationDataset` class.
   - Displays 10 random samples with their labels.
   - Inspects dataset properties (1000 samples, 283 vulnerable, 717 non-vulnerable, ratio=0.3947).
   - Loads the pre-trained `VulnPredictModel` and makes predictions.
   - Computes performance metrics:
     - True Positives (TP): 20
     - True Negatives (TN): 716
     - False Positives (FP): 1
     - False Negatives (FN): 263
     - Accuracy: 0.7360
     - Precision: 0.9524
     - Recall: 0.0707
     - F1-Score: 0.1316

## Results
- **Dataset**: 1000 samples (28.3% vulnerable, 71.7% non-vulnerable).
- **Metrics**:
  - Accuracy: 0.7360
  - Precision: 0.9524
  - Recall: 0.0707
  - F1-Score: 0.1316
- **Analysis**: The model achieves high precision but very low recall, missing most vulnerabilities (high false negatives). This suggests it is biased toward predicting non-vulnerable samples, likely due to the imbalanced dataset.

## Notes
- Ensure the HDF5 dataset and model weights are accessible in the specified paths.
- The low recall indicates the model is unsuitable for critical security applications without further tuning.

# Cybersecurity Data Science PBL Project - Part 2: Dataset Creation

## Overview
This part of the PBL project involves creating a labeled dataset of vulnerable and fixed Java methods from the ProjectKB repository. The dataset is generated by downloading the ProjectKB dataset, extracting repository URLs and commit IDs, identifying modified methods in Java files, and saving them in a JSON format with labels (`is_vulnerable: True` for vulnerable, `False` for fixed).

## Repository Structure
- `dataset_msr2019.csv`: ProjectKB dataset containing CVE and commit information.
- `repos_and_commits.csv`: Extracted repository URLs and commit IDs.
- `method_data/`: Directory containing extracted vulnerable and fixed methods.
- `labeled_methods_dataset.json`: Generated dataset of labeled methods.
- `part2_dataset_creation.py`: Script for downloading ProjectKB data and creating the dataset.
- `README_Part2.md`: This file.

## Requirements
Install the required Python packages:
```bash
pip install requests gitpython
```

## Usage
1. Run the dataset creation script:
   ```bash
   python part2_dataset_creation.py
   ```
2. The script performs the following:
   - Downloads the ProjectKB dataset (`dataset_msr2019.csv`) from the URL: `https://raw.githubusercontent.com/SAP/project-kb/main/MSR2019/notebooks/dataset_msr2019.csv`.
   - Extracts repository URLs and commit IDs (1723 repositories).
   - Clones each repository, checks out the fixing commit, and compares it with the parent commit to identify modified Java methods.
   - Saves modified methods (vulnerable and fixed versions) to `method_data/`.
   - Creates a labeled dataset in `labeled_methods_dataset.json` with the structure:
     - `function_code`: Java method code.
     - `is_vulnerable`: Boolean label (`True` for vulnerable, `False` for fixed).

## Results
- **Dataset**: Balanced dataset with equal numbers of vulnerable and fixed methods, extracted from 1723 repositories.
- **Output**: `labeled_methods_dataset.json` contains method pairs with labels.
- **Challenges**: Some repositories may fail to clone due to Git errors, and regex-based method extraction may miss complex method structures.


## Notes
- Ensure Git is installed for repository cloning.
- The dataset size depends on the number of modified methods extracted; inspect `labeled_methods_dataset.json` for the exact count.
- Consider using a more robust parser (e.g., Java AST) for method extraction to improve accuracy.

# Cybersecurity Data Science PBL Project - Part 3: LSTM Model Training and Evaluation

## Overview
This part of the PBL project involves training and evaluating a bidirectional LSTM model (`VulnerabilityLSTM`) on the custom dataset created in Part 2 (`labeled_methods_dataset.json`). The tasks include preprocessing the dataset into character sequences, splitting it into train/validation/test sets, training the model with two configurations, and evaluating performance using standard metrics.

## Repository Structure
- `labeled_methods_dataset.json`: Labeled dataset of vulnerable and fixed methods.
- `part2_training.py`: Script for preprocessing, training, and evaluating the LSTM model.
- `vulnerability_model.pth`: Saved weights for Experiment 1 (Embedding=128, Hidden=128, Epochs=10).
- `vulnerability_model_1.pth`: Saved weights for Experiment 2 (Embedding=256, Hidden=256, Epochs=20).
- `loss_plot.png`: Plot of training and validation loss.
- `README_Part3.md`: This file.

## Requirements
Install the required Python packages:
```bash
pip install torch numpy pandas scikit-learn matplotlib
```

## Usage
1. Ensure `labeled_methods_dataset.json` is in the working directory.
2. Run the training script:
   ```bash
   python part2_training.py
   ```
3. The script performs the following:
   - Loads the JSON dataset and builds a character-level vocabulary.
   - Splits the dataset into train (80%), validation (10%), and test (10%) sets using stratified sampling.
   - Preprocesses code into padded sequences (max length=256).
   - Trains a bidirectional LSTM model with two configurations:
     - **Experiment 1**: Embedding_dim=128, Hidden_dim=128, Epochs=10, Learning_rate=0.001.
     - **Experiment 2**: Embedding_dim=256, Hidden_dim=256, Epochs=20, Learning_rate=0.001.
   - Uses Binary Cross-Entropy Loss and Adam optimizer.
   - Plots training/validation loss and saves to `loss_plot.png`.
   - Evaluates the model on the test set using Precision, Recall, F1-Score, and Confusion Matrix.
   - Saves model weights to `vulnerability_model.pth` (Experiment 1) and `vulnerability_model_1.pth` (Experiment 2).

## Results
- **Dataset**: Balanced (equal vulnerable and fixed methods), with 102 test samples (51 per class).
- **Experiment 1** (Embedding=128, Hidden=128, Epochs=10):
  - Accuracy: 0.44
  - Macro F1-Score: 0.44
  - Confusion Matrix: [[18, 33], [24, 27]]
- **Experiment 2** (Embedding=256, Hidden=256, Epochs=20):
  - Accuracy: 0.39
  - Macro F1-Score: 0.39
  - Confusion Matrix: [[18, 33], [29, 22]]
- **Analysis**: Both experiments show poor performance, with Experiment 2 performing slightly worse, possibly due to overfitting from increased model complexity. Character-level preprocessing may be insufficient for capturing code semantics.


## Notes
- The poor performance suggests using token-level preprocessing (e.g., CodeBERT) or a Transformer-based model for better code representation.
- Increase training data size or adjust hyperparameters (e.g., learning rate, dropout) to improve results.
- The loss plot (`loss_plot.png`) shows increasing validation loss, indicating potential overfitting.